#!/usr/bin/env python
#
# Todo: Read config file, use target as test for urlopen2
# Todo: Check to make sure we don't duplicate queue files
#

import urllib2, urllib, httplib, json
import logging
import hashlib
from os import path,walk,remove,environ
import sys
sys.path.append("../lib")
from ti_orm import TiORM
from os.path import dirname, realpath, isfile, join, splitext, basename
from binascii import b2a_hex,hexlify
#from titantools.orm import TiORM
from titantools.system import shell_out
from zlib import compress
from time import sleep,strftime,gmtime,mktime
from sys import exit
import ConfigParser

# Get Titan Env and Config
TITAN_PATH = (environ.get('TITAN_PATH') or '/usr/local/titan/')
TITAN_CONFIG = join(TITAN_PATH, 'titan.conf')

# Set datastore
DATASTORE = join(TITAN_PATH, "db", "titan.sqlite")

# Load ORM 
ORM = TiORM(DATASTORE)
# Load default schema
ORM.initialize_table('watcher', {u'date': {u'nullable': False, u'type': u'text'}, 
								u'utime': {u'type': u'integer'}, 
								u'status': {u'type': u'integer'}})

# Device Serial
DEVICEID = shell_out("ioreg -c IOPlatformExpertDevice |head -30 |grep IOPlatformSerialNumber | awk '{print $4}'")[1:-2]

# Load Configuration
Config = ConfigParser.SafeConfigParser()
if path.isfile( TITAN_CONFIG ):
 	
 	# Read the config file
 	Config.read( TITAN_CONFIG )

 	# Set Log Path
 	REPORTING_TARGET = Config.get('reporting', 'target')

else:
  print "[!] Please create titan.conf"
  exit()

# Check if Watcher is enabled
if Config.get('watcher', 'enabled') is "false":
	print "[!] Watcher is disabled"
	exit()

# Configure Logging
logging.basicConfig(format='%(message)s', level=logging.INFO)

def generate_reports():

	# Report Timestamp
	unix_time = int(mktime(gmtime()))
	exec_time = strftime("%a, %d %b %Y %H:%M:%S", gmtime())

	print unix_time

	# Query all tables
	all_tables = ORM.select('sqlite_master', 'name',  "type = 'table' and name != 'watcher'")

	# Last success
	last_success = ORM.raw_sql('SELECT * FROM watcher WHERE status=1 ORDER BY date DESC LIMIT 1')
	if len(last_success) > 0:
		last_success = last_success[0]

	# How many wins do we need
	passes_needed = len(all_tables)
	passes_had = 0

	# Loop through tables
	for table in [table for table in all_tables]:
			
		# Get table data
		if len(last_success) is 0:
			# Logging is cool
			logging.info("Collecting data for [%s] since ever" % (table['name']))
			results = ORM.select(table['name'], '*')
		else:
			# Logging is cool
			print last_success
			logging.info("Collecting data for [%s] since %s" % (table['name'],last_success[1]))
			results = ORM.select(table['name'], '*', 'unixtime > %s' % last_success[3])

		print results
		
		if results is None or len(results) == 0:
			continue

		# Dump table to json
		table_json = json.dumps(results)

		# Compress the data
		compressed = compress(table_json)

		# Digest
		content_digest = hashlib.sha256(compressed).hexdigest()

		# Send the table data upstream
		target = "%s%s" % (REPORTING_TARGET, DEVICEID)
		logging.info("\tSending request to '%s'" % target)
		code, response = send_request(target, {'serial': DEVICEID, 'digest': content_digest, 'stream': compressed})
		logging.info("\tResponse: [%d]" % (code))

		if code == 200:
			passes_had += 1

	# If all data has been uploaded
	# update watcher table
	if passes_had == passes_needed:
		response = {'utime': str(unix_time), 'date': exec_time, 'status': str(1)};
		ORM.insert('watcher', response)
	else:
		response = {'utime': str(unix_time), 'date': exec_time, 'status': str(0)};
		ORM.insert('watcher', response)

	print ORM.select('watcher')
	exit()


# Send the request
def send_request( target, data):
	try:
		request = urllib2.Request(target, urllib.urlencode(data) )
		opener = urllib2.build_opener()
		response = opener.open(request)
		response_object = response.getcode(), response

	except urllib2.HTTPError, e:
		if e.code == 307:
			for line in str(e.headers).splitlines():
				if "Location" in line:
					new_target = line.split(": ", 1)[1]
					response_object = send_request( new_target, data )
		else:
			response_object = e.code, e.read()

	except urllib2.URLError, e:
		f = open( join( LOG_PATH, "/queue_%s.log" % sysdic['time'] ),'w')
		f.write(json.dumps(sysdic))
		f.close()
		response_object = 0, 'Connection Refused'

	return response_object


# Check if internet is available
while True:
	try:
		is_connected = urllib2.urlopen( REPORTING_TARGET )

	except urllib2.URLError:
		logging.info("Titan Watcher did not detect a connection, retrying in 3 seconds")
		sleep(float(Config.get('watcher', 'timeout')))

	else:
		logging.info("Titan Watcher detected a connection")
		
		generate_reports()

 		sleep(float(Config.get('watcher', 'send_every')))
